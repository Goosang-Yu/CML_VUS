{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SupplementaryCode2\n",
    "#### pegRNA_abundance_screening_analysis\n",
    "\n",
    "CML VUS screening 결과 중, pegRNA abundance screening의 NGS data를 분석하기 위해 수행한 preprocessing용 python script. For more detail, please read Methods and Supplementary Information. \n",
    "\n",
    "Lead contact: Hyoungbum Henry Kim (hkim1@gmail.com)\n",
    "\n",
    "Technical contact: Goosang Yu (gsyu93@gmail.com), Yusang Jung (ys.jung@yuhs.ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "아래의 pipeline은 linux 환경에서 사용하는 것을 전제로 제작되었음. Ubuntu 22.04 LTS 또는 CentOS7에서 테스트 확인되었음.  \n",
    "아래의 pipeline을 수행하기 위해서, 다음의 software들이 설치되어 있어야 함. \n",
    "- python (>= 3.8)\n",
    "- genet (>= 0.14)\n",
    "- cutadapt\n",
    "- seqkit\n",
    "- MAGeCK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory tree\n",
    "아래의 pipeline은 다음의 directory 구조로 구성되어 있음을 전제로 제작되었음.\n",
    "\n",
    "📦Working directory  \n",
    " ┣ 📂0_barcode_info  \n",
    " ┃ ┗ 📜epegRNA_lib_reference.csv  \n",
    " ┣ 📂1_raw_data  \n",
    " ┃ ┣ 📜epeg_DMSO_A_merged_2.fq.gz  \n",
    " ┃ ┣ 📜epeg_DMSO_B_merged_2.fq.gz  \n",
    " ┃ ┣ 📜epeg_Imatinib_A_merged_2.fq.gz  \n",
    " ┃ ┗ 📜epeg_Imatinib_B_merged_2.fq.gz  \n",
    " ┣ 📂2_processed  \n",
    " ┣ 📂3_results  \n",
    " ┣ 📂4_mageck  \n",
    " ┣ 📂src  \n",
    " ┃ ┗ 📜preprocessing.py  \n",
    " ┗ 📜SuppleCodeXX.ipynb (this file)  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Import packagies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys, os, time, glob, gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO\n",
    "from datetime import datetime\n",
    "from genet.analysis import ReadDeduplicator\n",
    "from src.preprocessing import Preprocess, make_df_umi, MAGeCKanalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Preprocessing NGS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = [   \n",
    "    \"/extdata2/CML_vus/10_NBT_revision/1_raw_data/epeg_DMSO_A_merged_2.fq.gz\",\n",
    "    \"/extdata2/CML_vus/10_NBT_revision/1_raw_data/epeg_DMSO_B_merged_2.fq.gz\",\n",
    "    \"/extdata2/CML_vus/10_NBT_revision/1_raw_data/epeg_Imatinib_A_merged_2.fq.gz\",\n",
    "    \"/extdata2/CML_vus/10_NBT_revision/1_raw_data/epeg_Imatinib_B_merged_2.fq.gz\"\n",
    "]\n",
    "\n",
    "def current_time():\n",
    "    return str(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "def worker(seq_path:str):\n",
    "    \n",
    "    with open('preprocess.log', 'a+') as file:\n",
    "        \n",
    "        print(current_time())\n",
    "        print('Step 0: Load data and initiation\\n')\n",
    "        file.write(f'{current_time()} Step 0: Load data and initiation')\n",
    "        data_pp = Preprocess(data_path=seq_path, data_format='fq.gz')\n",
    "\n",
    "        print('Step 1: to_fasta')\n",
    "        file.write(f'{current_time()} Step 1: to_fasta\\n')\n",
    "        path = data_pp.to_fasta(gzip=True)\n",
    "        print(f'[Done] save - {path}\\n')\n",
    "        file.write(f'{current_time()} [Done] save - {path}\\n')\n",
    "\n",
    "        print('Step 2: trim tevopreQ1 seq')\n",
    "        file.write(f'{current_time()} Step 2: trim tevopreQ1 seq\\n')\n",
    "        path = data_pp.trim(finder='AAAAAATTCTAG', error=0)\n",
    "        print(f'[Done] save - {path}\\n')\n",
    "        file.write(f'{current_time()} [Done] save - {path}\\n')\n",
    "\n",
    "        print('Step 3: revcom seq')\n",
    "        file.write(f'{current_time()} Step 3: revcom seq\\n')\n",
    "        path = data_pp.revcom()\n",
    "        print(f'[Done] save - {path}\\n')\n",
    "        file.write(f'{current_time()} [Done] save - {path}\\n')\n",
    "\n",
    "        print('Step 4: trim RP binding seq')\n",
    "        file.write(f'{current_time()} Step 4: trim RP binding seq\\n')\n",
    "        path = data_pp.trim(finder='CTACTCTACCACTTGT', error=1)\n",
    "        print(f'[Done] save - {path}\\n')\n",
    "        file.write(f'{current_time()} [Done] save - {path}\\n')\n",
    "\n",
    "        print('Step 5: Finalize')\n",
    "        file.write(f'{current_time()} Step 5: Finalize\\n')\n",
    "        path = data_pp.finalize(save_path='2_processed')\n",
    "        print(f'[Done] save - {path}\\n')\n",
    "        file.write(f'{current_time()} [Done] save - {path}\\n')\n",
    "\n",
    "for seq_path in list_files:\n",
    "    worker(seq_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: UMI counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_sample_id = [\n",
    "    'pp_epeg_DMSO_A_merged_2',\n",
    "    'pp_epeg_DMSO_B_merged_2',\n",
    "    'pp_epeg_Imatinib_A_merged_2',\n",
    "    'pp_epeg_Imatinib_B_merged_2',\n",
    "]\n",
    "\n",
    "df_barcode = pd.read_csv('CML_VUS_Barcode_SNV_final.csv')\n",
    "\n",
    "\n",
    "for sample in list_sample_id:\n",
    "\n",
    "    fa = f'2_processed/{sample}.fa.gz'\n",
    "    f_name = fa.split('/')[-1]\n",
    "\n",
    "    print('Parsing sequencing data...')\n",
    "    df_umi = make_df_umi(list_barcode=list(df_barcode['Barcode for sorting (18nt)']),\n",
    "                         data_path=fa,\n",
    "                         len_umi=8,\n",
    "                        )\n",
    "\n",
    "    df_umi.to_csv('3_results/%s' % f_name.replace('.fa.gz', '_UMI_duplicated.csv'),)\n",
    "\n",
    "    umi_group = df_umi.groupby(by=['Barcode'])\n",
    "    list_bc   = df_umi['Barcode'].unique()\n",
    "\n",
    "    list_df = []\n",
    "\n",
    "    for bc in tqdm(list_bc, total = len(list_bc),\n",
    "                   desc = 'UMI deduplication',\n",
    "                   ncols=70, ascii=' =', leave=True\n",
    "                   ):\n",
    "        \n",
    "        dict_out  = {'Barcode'  : [bc]*4, \n",
    "                     'UMI_dedup': ['startA', 'startC', 'startG', 'startT'], \n",
    "                     'count'    : [0, 0, 0, 0]}\n",
    "\n",
    "        umis_dupple = umi_group.get_group(bc)\n",
    "        \n",
    "        # UMI-tools: ReadDeduplicator\n",
    "        dedup = ReadDeduplicator()\n",
    "        final_umis, umi_counts = dedup(umis_dupple, threshold=1)\n",
    "\n",
    "        for umi, cnt in zip(final_umis, umi_counts):\n",
    "            \n",
    "            start_umi = umi[0]\n",
    "            \n",
    "            if   start_umi == 'A': dict_out['count'][0] += cnt\n",
    "            elif start_umi == 'C': dict_out['count'][1] += cnt\n",
    "            elif start_umi == 'G': dict_out['count'][2] += cnt\n",
    "            elif start_umi == 'T': dict_out['count'][3] += cnt\n",
    "\n",
    "        df_dedup = pd.DataFrame.from_dict(data=dict_out, orient='columns')\n",
    "        list_df.append(df_dedup)\n",
    "    \n",
    "    df_out = pd.concat(list_df).reset_index(drop=True)\n",
    "\n",
    "    df_out.to_csv(\"3_results/%s\" % f_name.replace('.fa.gz', '_UMI_dedup_ATGC_subgroup.csv'),\n",
    "                    index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: MAGeCK analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference file path\n",
    "lib_reference = '0_barcode_info/epegRNA_lib_reference.csv'\n",
    "\n",
    "# Step1: Make mageck input file for each replicate\n",
    "print('Step1: Make mageck input file for each replicate')\n",
    "for rep in ['A', 'B']:\n",
    "\n",
    "    dmso_umi_path = f'3_results/pp_epeg_DMSO_{rep}_merged_2_UMI_dedup_ATGC_subgroup.csv'\n",
    "    tki_umi_path  = f'3_results/pp_epeg_Imatinib_{rep}_merged_2_UMI_dedup_ATGC_subgroup.csv'\n",
    "\n",
    "    mageck = MAGeCKanalyzer()\n",
    "\n",
    "    df_count = mageck.setup(lib_reference=lib_reference,\n",
    "                            dmso_umi_path=dmso_umi_path, \n",
    "                            tki_umi_path=tki_umi_path\n",
    "                            )\n",
    "    \n",
    "    df_count.to_csv(f'4_mageck/mageck_count_Imatinib_{rep}_AA_var.csv')\n",
    "\n",
    "# Step2: Make average RPM files\n",
    "print('Step2: Make average RPM files')\n",
    "df_a = pd.read_csv('4_mageck/mageck_count_Imatinib_A_AA_var.csv', index_col='Barcode-UMI')\n",
    "df_b = pd.read_csv('4_mageck/mageck_count_Imatinib_B_AA_var.csv', index_col='Barcode-UMI')\n",
    "\n",
    "df_merge = df_a.copy()\n",
    "\n",
    "df_merge['control'] = (df_a['control'] + df_b['control']) / 2\n",
    "df_merge['test'] = (df_a['test'] + df_b['test']) / 2\n",
    "\n",
    "df_merge.to_csv('4_mageck/mageck_count_Imatinib_merge_AA_var.csv')\n",
    "\n",
    "\n",
    "# Step3: Run MAGeCK\n",
    "print('Step3: Run MAGeCK')\n",
    "mageck = MAGeCKanalyzer()\n",
    "\n",
    "result = mageck.mageck(input_file='4_mageck/mageck_count_Imatinib_merge_AA_var.csv',\n",
    "                       name='Imatinib_revision', save_path='4_mageck')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
