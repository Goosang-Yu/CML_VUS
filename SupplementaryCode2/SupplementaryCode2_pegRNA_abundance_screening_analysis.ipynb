{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SupplementaryCode2\n",
    "#### pegRNA_abundance_screening_analysis\n",
    "\n",
    "CML VUS screening ê²°ê³¼ ì¤‘, pegRNA abundance screeningì˜ NGS dataë¥¼ ë¶„ì„í•˜ê¸° ìœ„í•´ ìˆ˜í–‰í•œ preprocessingìš© python script. For more detail, please read Methods and Supplementary Information. \n",
    "\n",
    "Lead contact: Hyoungbum Henry Kim (hkim1@gmail.com)\n",
    "\n",
    "Technical contact: Goosang Yu (gsyu93@gmail.com), Yusang Jung (ys.jung@yuhs.ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "ì•„ë˜ì˜ pipelineì€ linux í™˜ê²½ì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ì „ì œë¡œ ì œì‘ë˜ì—ˆìŒ. Ubuntu 22.04 LTS ë˜ëŠ” CentOS7ì—ì„œ í…ŒìŠ¤íŠ¸ í™•ì¸ë˜ì—ˆìŒ.  \n",
    "ì•„ë˜ì˜ pipelineì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ì„œ, ë‹¤ìŒì˜ softwareë“¤ì´ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•¨. \n",
    "- python (>= 3.8)\n",
    "- genet (>= 0.14)\n",
    "- cutadapt\n",
    "- seqkit\n",
    "- MAGeCK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory tree\n",
    "ì•„ë˜ì˜ pipelineì€ ë‹¤ìŒì˜ directory êµ¬ì¡°ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŒì„ ì „ì œë¡œ ì œì‘ë˜ì—ˆìŒ.\n",
    "\n",
    "ğŸ“¦Working directory  \n",
    " â”£ ğŸ“‚0_barcode_info  \n",
    " â”ƒ â”— ğŸ“œepegRNA_lib_reference.csv  \n",
    " â”£ ğŸ“‚1_raw_data  \n",
    " â”ƒ â”£ ğŸ“œepeg_DMSO_A_merged_2.fq.gz  \n",
    " â”ƒ â”£ ğŸ“œepeg_DMSO_B_merged_2.fq.gz  \n",
    " â”ƒ â”£ ğŸ“œepeg_Imatinib_A_merged_2.fq.gz  \n",
    " â”ƒ â”— ğŸ“œepeg_Imatinib_B_merged_2.fq.gz  \n",
    " â”£ ğŸ“‚2_processed  \n",
    " â”£ ğŸ“‚3_results  \n",
    " â”£ ğŸ“‚4_mageck  \n",
    " â”£ ğŸ“‚src  \n",
    " â”ƒ â”— ğŸ“œpreprocessing.py  \n",
    " â”— ğŸ“œSuppleCodeXX.ipynb (this file)  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Import packagies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys, os, time, glob, gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO\n",
    "from datetime import datetime\n",
    "from genet.analysis import ReadDeduplicator\n",
    "from src.preprocessing import Preprocess, make_df_umi, MAGeCKanalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Preprocessing NGS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = [   \n",
    "    \"/extdata2/CML_vus/10_NBT_revision/1_raw_data/epeg_DMSO_A_merged_2.fq.gz\",\n",
    "    \"/extdata2/CML_vus/10_NBT_revision/1_raw_data/epeg_DMSO_B_merged_2.fq.gz\",\n",
    "    \"/extdata2/CML_vus/10_NBT_revision/1_raw_data/epeg_Imatinib_A_merged_2.fq.gz\",\n",
    "    \"/extdata2/CML_vus/10_NBT_revision/1_raw_data/epeg_Imatinib_B_merged_2.fq.gz\"\n",
    "]\n",
    "\n",
    "def current_time():\n",
    "    return str(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "def worker(seq_path:str):\n",
    "    \n",
    "    with open('preprocess.log', 'a+') as file:\n",
    "        \n",
    "        print(current_time())\n",
    "        print('Step 0: Load data and initiation\\n')\n",
    "        file.write(f'{current_time()} Step 0: Load data and initiation')\n",
    "        data_pp = Preprocess(data_path=seq_path, data_format='fq.gz')\n",
    "\n",
    "        print('Step 1: to_fasta')\n",
    "        file.write(f'{current_time()} Step 1: to_fasta\\n')\n",
    "        path = data_pp.to_fasta(gzip=True)\n",
    "        print(f'[Done] save - {path}\\n')\n",
    "        file.write(f'{current_time()} [Done] save - {path}\\n')\n",
    "\n",
    "        print('Step 2: trim tevopreQ1 seq')\n",
    "        file.write(f'{current_time()} Step 2: trim tevopreQ1 seq\\n')\n",
    "        path = data_pp.trim(finder='AAAAAATTCTAG', error=0)\n",
    "        print(f'[Done] save - {path}\\n')\n",
    "        file.write(f'{current_time()} [Done] save - {path}\\n')\n",
    "\n",
    "        print('Step 3: revcom seq')\n",
    "        file.write(f'{current_time()} Step 3: revcom seq\\n')\n",
    "        path = data_pp.revcom()\n",
    "        print(f'[Done] save - {path}\\n')\n",
    "        file.write(f'{current_time()} [Done] save - {path}\\n')\n",
    "\n",
    "        print('Step 4: trim RP binding seq')\n",
    "        file.write(f'{current_time()} Step 4: trim RP binding seq\\n')\n",
    "        path = data_pp.trim(finder='CTACTCTACCACTTGT', error=1)\n",
    "        print(f'[Done] save - {path}\\n')\n",
    "        file.write(f'{current_time()} [Done] save - {path}\\n')\n",
    "\n",
    "        print('Step 5: Finalize')\n",
    "        file.write(f'{current_time()} Step 5: Finalize\\n')\n",
    "        path = data_pp.finalize(save_path='2_processed')\n",
    "        print(f'[Done] save - {path}\\n')\n",
    "        file.write(f'{current_time()} [Done] save - {path}\\n')\n",
    "\n",
    "for seq_path in list_files:\n",
    "    worker(seq_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: UMI counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_sample_id = [\n",
    "    'pp_epeg_DMSO_A_merged_2',\n",
    "    'pp_epeg_DMSO_B_merged_2',\n",
    "    'pp_epeg_Imatinib_A_merged_2',\n",
    "    'pp_epeg_Imatinib_B_merged_2',\n",
    "]\n",
    "\n",
    "df_barcode = pd.read_csv('CML_VUS_Barcode_SNV_final.csv')\n",
    "\n",
    "\n",
    "for sample in list_sample_id:\n",
    "\n",
    "    fa = f'2_processed/{sample}.fa.gz'\n",
    "    f_name = fa.split('/')[-1]\n",
    "\n",
    "    print('Parsing sequencing data...')\n",
    "    df_umi = make_df_umi(list_barcode=list(df_barcode['Barcode for sorting (18nt)']),\n",
    "                         data_path=fa,\n",
    "                         len_umi=8,\n",
    "                        )\n",
    "\n",
    "    df_umi.to_csv('3_results/%s' % f_name.replace('.fa.gz', '_UMI_duplicated.csv'),)\n",
    "\n",
    "    umi_group = df_umi.groupby(by=['Barcode'])\n",
    "    list_bc   = df_umi['Barcode'].unique()\n",
    "\n",
    "    list_df = []\n",
    "\n",
    "    for bc in tqdm(list_bc, total = len(list_bc),\n",
    "                   desc = 'UMI deduplication',\n",
    "                   ncols=70, ascii=' =', leave=True\n",
    "                   ):\n",
    "        \n",
    "        dict_out  = {'Barcode'  : [bc]*4, \n",
    "                     'UMI_dedup': ['startA', 'startC', 'startG', 'startT'], \n",
    "                     'count'    : [0, 0, 0, 0]}\n",
    "\n",
    "        umis_dupple = umi_group.get_group(bc)\n",
    "        \n",
    "        # UMI-tools: ReadDeduplicator\n",
    "        dedup = ReadDeduplicator()\n",
    "        final_umis, umi_counts = dedup(umis_dupple, threshold=1)\n",
    "\n",
    "        for umi, cnt in zip(final_umis, umi_counts):\n",
    "            \n",
    "            start_umi = umi[0]\n",
    "            \n",
    "            if   start_umi == 'A': dict_out['count'][0] += cnt\n",
    "            elif start_umi == 'C': dict_out['count'][1] += cnt\n",
    "            elif start_umi == 'G': dict_out['count'][2] += cnt\n",
    "            elif start_umi == 'T': dict_out['count'][3] += cnt\n",
    "\n",
    "        df_dedup = pd.DataFrame.from_dict(data=dict_out, orient='columns')\n",
    "        list_df.append(df_dedup)\n",
    "    \n",
    "    df_out = pd.concat(list_df).reset_index(drop=True)\n",
    "\n",
    "    df_out.to_csv(\"3_results/%s\" % f_name.replace('.fa.gz', '_UMI_dedup_ATGC_subgroup.csv'),\n",
    "                    index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: MAGeCK analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference file path\n",
    "lib_reference = '0_barcode_info/epegRNA_lib_reference.csv'\n",
    "\n",
    "# Step1: Make mageck input file for each replicate\n",
    "print('Step1: Make mageck input file for each replicate')\n",
    "for rep in ['A', 'B']:\n",
    "\n",
    "    dmso_umi_path = f'3_results/pp_epeg_DMSO_{rep}_merged_2_UMI_dedup_ATGC_subgroup.csv'\n",
    "    tki_umi_path  = f'3_results/pp_epeg_Imatinib_{rep}_merged_2_UMI_dedup_ATGC_subgroup.csv'\n",
    "\n",
    "    mageck = MAGeCKanalyzer()\n",
    "\n",
    "    df_count = mageck.setup(lib_reference=lib_reference,\n",
    "                            dmso_umi_path=dmso_umi_path, \n",
    "                            tki_umi_path=tki_umi_path\n",
    "                            )\n",
    "    \n",
    "    df_count.to_csv(f'4_mageck/mageck_count_Imatinib_{rep}_AA_var.csv')\n",
    "\n",
    "# Step2: Make average RPM files\n",
    "print('Step2: Make average RPM files')\n",
    "df_a = pd.read_csv('4_mageck/mageck_count_Imatinib_A_AA_var.csv', index_col='Barcode-UMI')\n",
    "df_b = pd.read_csv('4_mageck/mageck_count_Imatinib_B_AA_var.csv', index_col='Barcode-UMI')\n",
    "\n",
    "df_merge = df_a.copy()\n",
    "\n",
    "df_merge['control'] = (df_a['control'] + df_b['control']) / 2\n",
    "df_merge['test'] = (df_a['test'] + df_b['test']) / 2\n",
    "\n",
    "df_merge.to_csv('4_mageck/mageck_count_Imatinib_merge_AA_var.csv')\n",
    "\n",
    "\n",
    "# Step3: Run MAGeCK\n",
    "print('Step3: Run MAGeCK')\n",
    "mageck = MAGeCKanalyzer()\n",
    "\n",
    "result = mageck.mageck(input_file='4_mageck/mageck_count_Imatinib_merge_AA_var.csv',\n",
    "                       name='Imatinib_revision', save_path='4_mageck')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
