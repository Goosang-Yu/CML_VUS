{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Supplementary Code 1**\n",
    "This notebook was used for designing library for pegRNA abundance screening. For more detail, please read Methods and Supplementary Information. \n",
    "\n",
    "Lead contact: Hyoungbum Henry Kim (hkim1@gmail.com)\n",
    "\n",
    "Technical contact: Goosang Yu (gsyu93@gmail.com), Yusang Jung (ys.jung@yuhs.ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory tree\n",
    "\n",
    "📦Working directory  \n",
    " ┣ 📂input  \n",
    " ┃ ┗ 📜ABL1_ex4.csv  \n",
    " ┃ ┗ 📜ABL1_ex5.csv  \n",
    " ┃ ┗ 📜...  \n",
    " ┗ 📂output  \n",
    " ┃ ┗ 📂ABL1_ex4  \n",
    " ┃ ┃ ┗ 📜ABL1_ex4_pos1T_A_output.parquet  \n",
    " ┃ ┃ ┗ 📜ABL1_ex4_pos1T_C_output.parquet  \n",
    " ┃ ┃ ┗ 📜...  \n",
    " ┃ ┗ 📂ABL1_ex5  \n",
    " ┃ ┃ ┗ 📜ABL1_ex5_pos1T_A_output.parquet  \n",
    " ┃ ┃ ┗ 📜ABL1_ex5_pos1T_C_output.parquet  \n",
    " ┃ ┃ ┗ 📜...  \n",
    " ┗ 📜SuppleCode1.ipynb (this file)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Make reference sequence pair\n",
    "Reference sequence pair is composed with unedited and edited (with SNV) sequences for each variants. This file was generated by Excel. For example, please check Supplementary Table XX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Design pegRNAs and get DeepPrime score\n",
    "Using DeepPrime-FT model (Yu et al., Cell, 2023), we designed all available pegRNAs and get predicted prime editing scores for each SNV as bellow.  \n",
    "\n",
    "For using DeepPrime, we used python package 'GenET' version 0.8x or higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "from glob import glob\n",
    "from genet import predict as prd\n",
    "\n",
    "# Set input / output file name \n",
    "sample_tag = 'ABL1_ex4'\n",
    "\n",
    "OUT_DIR    = './output/%s' % sample_tag\n",
    "os.mkdir(OUT_DIR)\n",
    "\n",
    "# load reference sequence pair file described in 'Step 1'\n",
    "df_input = pd.read_csv('./input/%s.csv' % sample_tag)\n",
    "\n",
    "for idx in df_input.index:\n",
    "    \n",
    "    print('Index: %s' % idx)\n",
    "    \n",
    "    info = df_input.iloc[idx]\n",
    "\n",
    "    sID    = info.ID\n",
    "    seq_wt = info.Ref\n",
    "    seq_ed = info.Edit\n",
    "    alt_type = 'sub1'\n",
    "\n",
    "    print('Variant ID: ', sID)\n",
    "    df_pe_score = prd.pe_score(seq_wt, seq_ed, alt_type, sID=sID, pbs_min=6, pbs_max=17, pe_system='PE2max', cell_type='DLD1')\n",
    "\n",
    "    df_pe_score.to_parquet('%s/%s_output.parquet' % (OUT_DIR, sID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Select best pegRNAs for screening\n",
    "Based on DeepPrime-FT score, we selected 6 pegRNAs for each varinat as bellow. After then, we only choose 3 pegRNAs for each variants for final list of library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_complement(sSeq):\n",
    "    dict_sBases = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N', 'U': 'U', 'n': '',\n",
    "                   '.': '.', '*': '*', 'a': 't', 'c': 'g', 'g': 'c', 't': 'a'}\n",
    "    list_sSeq = list(sSeq)  # Turns the sequence in to a gigantic list\n",
    "    list_sSeq = [dict_sBases[sBase] for sBase in list_sSeq]\n",
    "    return ''.join(list_sSeq)[::-1]\n",
    "\n",
    "# def END: reverse_complement\n",
    "\n",
    "def make_top_pegrna_list(file_dir, pe_sys):\n",
    "\n",
    "    ## Target directory에 있는 모든 feather file을 모아준다. \n",
    "    file_list = list(glob('%s/%s/results/*.parquet' % (file_dir, pe_sys)))\n",
    "    df_out = pd.DataFrame()\n",
    "\n",
    "    for f in file_list:\n",
    "\n",
    "        ## 1. sort_values('DeepPrime_score')\n",
    "        df = pd.read_parquet(f)\n",
    "        df = df.sort_values('DeepPrime_score', ascending=False)\n",
    "\n",
    "        ## 추가!! RT-PBS에 BsmBI site가 들어있는 것 제거하기\n",
    "        ## ED seq에서 찾아보면 된다. 양방향 둘 다에서 찾을 것이기 때문.\n",
    "        df = df[~df['Edited74_On'].str.contains('GAGACG', na=False, case=False)]\n",
    "        df = df[~df['Edited74_On'].str.contains('CGTCTC', na=False, case=False)]\n",
    "\n",
    "        ## 추가!! spacer 부분에서 BsmBI site가 들어있는 것 제거하기\n",
    "        ## WT target에서 spacer 부분만 뽑은 것을 새 column으로 넣고, 똑같이 제거해주면 된다. \n",
    "        df['gN19'] = df['WT74_On'][5:24]\n",
    "        df = df[~df['gN19'].str.contains('GAGACG', na=False, case=False)]\n",
    "        df = df[~df['gN19'].str.contains('CGTCTC', na=False, case=False)]\n",
    "\n",
    "        ## 2. target만 series로 가져온 다음, unique value만 남긴다. sorting을 먼저 했기 때문에 DeepPrime score 높은 것이 가장 먼저 나온 순으로 정렬된다. = srs_target (srs = series 약자)\n",
    "        srs_target = df.WT74_On.unique()\n",
    "\n",
    "        ## 3. sort_values 된 df를 Seed target으로 groupby한다.\n",
    "        grouped_df = df.groupby('WT74_On')\n",
    "\n",
    "        ## 4. ser_target에서 앞에서 3개에 대해서만 (top3) 각 seed target마다 top 3개씩 고른다. 총 3개의 seed에 대해 9개의 pegRNA가 선정되어야 함.\n",
    "        ## Seed Target이 3개 이하일 수 있으니 for문으로 len(srs_target)만큼 돌리다가 3개 넘어가는 idx 3 넘기는 순간 continue.\n",
    "        \n",
    "        list_df_temp = []\n",
    "\n",
    "        for idx, trgt in enumerate(srs_target):\n",
    "            df_top3_pegrna = grouped_df.get_group(trgt).head(2)\n",
    "            list_df_temp.append(df_top3_pegrna)\n",
    "\n",
    "            if idx == 2: break\n",
    "        \n",
    "        ## 5. Output = 이렇게 뽑힌 pegRNA 정보들은 새 dataframe들에 담아준다. 그리고 그 안에서 rank column을 추가해준다. 그리고 최종 output df에 넣어준다. \n",
    "        df_temp = pd.concat(list_df_temp)\n",
    "        df_temp['rank'] = df_temp.DeepPrime_score.rank(ascending=False)\n",
    "        \n",
    "        df_out = pd.concat([df_out, df_temp])\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run ###\n",
    "\n",
    "target_list = ['ABL1_ex4', 'ABL1_ex5', 'ABL1_ex6', 'ABL1_ex7', 'ABL1_ex8', 'ABL1_ex9']\n",
    "pe_sys = ['PE2max']\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "\n",
    "for pe in pe_sys:\n",
    "    list_out = []\n",
    "\n",
    "    for gene in target_list:\n",
    "        file_dir = '%s/output/%s' %(base_dir, gene)\n",
    "\n",
    "        df_out = make_top_pegrna_list(file_dir, pe)\n",
    "        list_out.append(df_out)\n",
    "\n",
    "    df = pd.concat(list_out)\n",
    "    df.to_csv('%s/ABL1_top_pegRNAs_%s_220802_BsmBI_filtered_Top6.csv' % (base_dir, pe), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
