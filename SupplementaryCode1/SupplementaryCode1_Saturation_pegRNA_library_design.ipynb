{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Supplementary Code 1**\n",
    "This notebook was used for designing library for pegRNA abundance screening. For more detail, please read Methods and Supplementary Information. \n",
    "\n",
    "Lead contact: Hyoungbum Henry Kim (hkim1@gmail.com)\n",
    "\n",
    "Technical contact: Goosang Yu (gsyu93@gmail.com), Yusang Jung (ys.jung@yuhs.ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory tree\n",
    "\n",
    "ğŸ“¦Working directory  \n",
    " â”£ ğŸ“‚input  \n",
    " â”ƒ â”— ğŸ“œABL1_ex4.csv  \n",
    " â”ƒ â”— ğŸ“œABL1_ex5.csv  \n",
    " â”ƒ â”— ğŸ“œ...  \n",
    " â”— ğŸ“‚output  \n",
    " â”ƒ â”— ğŸ“‚ABL1_ex4  \n",
    " â”ƒ â”ƒ â”— ğŸ“œABL1_ex4_pos1T_A_output.parquet  \n",
    " â”ƒ â”ƒ â”— ğŸ“œABL1_ex4_pos1T_C_output.parquet  \n",
    " â”ƒ â”ƒ â”— ğŸ“œ...  \n",
    " â”ƒ â”— ğŸ“‚ABL1_ex5  \n",
    " â”ƒ â”ƒ â”— ğŸ“œABL1_ex5_pos1T_A_output.parquet  \n",
    " â”ƒ â”ƒ â”— ğŸ“œABL1_ex5_pos1T_C_output.parquet  \n",
    " â”ƒ â”ƒ â”— ğŸ“œ...  \n",
    " â”— ğŸ“œSuppleCode1.ipynb (this file)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Make reference sequence pair\n",
    "Reference sequence pair is composed with unedited and edited (with SNV) sequences for each variants. This file was generated by Excel. For example, please check Supplementary Table XX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Design pegRNAs and get DeepPrime score\n",
    "Using DeepPrime-FT model (Yu et al., Cell, 2023), we designed all available pegRNAs and get predicted prime editing scores for each SNV as bellow.  \n",
    "\n",
    "For using DeepPrime, we used python package 'GenET' version 0.8x or higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "from glob import glob\n",
    "from genet import predict as prd\n",
    "\n",
    "# Set input / output file name \n",
    "sample_tag = 'ABL1_ex4'\n",
    "\n",
    "OUT_DIR    = './output/%s' % sample_tag\n",
    "os.mkdir(OUT_DIR)\n",
    "\n",
    "# load reference sequence pair file described in 'Step 1'\n",
    "df_input = pd.read_csv('./input/%s.csv' % sample_tag)\n",
    "\n",
    "for idx in df_input.index:\n",
    "    \n",
    "    print('Index: %s' % idx)\n",
    "    \n",
    "    info = df_input.iloc[idx]\n",
    "\n",
    "    sID    = info.ID\n",
    "    seq_wt = info.Ref\n",
    "    seq_ed = info.Edit\n",
    "    alt_type = 'sub1'\n",
    "\n",
    "    print('Variant ID: ', sID)\n",
    "    df_pe_score = prd.pe_score(seq_wt, seq_ed, alt_type, sID=sID, pbs_min=6, pbs_max=17, pe_system='PE2max', cell_type='DLD1')\n",
    "\n",
    "    df_pe_score.to_parquet('%s/%s_output.parquet' % (OUT_DIR, sID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Select best pegRNAs for screening\n",
    "Based on DeepPrime-FT score, we selected 6 pegRNAs for each varinat as bellow. After then, we only choose 3 pegRNAs for each variants for final list of library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_complement(sSeq):\n",
    "    dict_sBases = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N', 'U': 'U', 'n': '',\n",
    "                   '.': '.', '*': '*', 'a': 't', 'c': 'g', 'g': 'c', 't': 'a'}\n",
    "    list_sSeq = list(sSeq)  # Turns the sequence in to a gigantic list\n",
    "    list_sSeq = [dict_sBases[sBase] for sBase in list_sSeq]\n",
    "    return ''.join(list_sSeq)[::-1]\n",
    "\n",
    "# def END: reverse_complement\n",
    "\n",
    "def make_top_pegrna_list(file_dir, pe_sys):\n",
    "\n",
    "    ## Target directoryì— ìˆëŠ” ëª¨ë“  feather fileì„ ëª¨ì•„ì¤€ë‹¤. \n",
    "    file_list = list(glob('%s/%s/results/*.parquet' % (file_dir, pe_sys)))\n",
    "    df_out = pd.DataFrame()\n",
    "\n",
    "    for f in file_list:\n",
    "\n",
    "        ## 1. sort_values('DeepPrime_score')\n",
    "        df = pd.read_parquet(f)\n",
    "        df = df.sort_values('DeepPrime_score', ascending=False)\n",
    "\n",
    "        ## ì¶”ê°€!! RT-PBSì— BsmBI siteê°€ ë“¤ì–´ìˆëŠ” ê²ƒ ì œê±°í•˜ê¸°\n",
    "        ## ED seqì—ì„œ ì°¾ì•„ë³´ë©´ ëœë‹¤. ì–‘ë°©í–¥ ë‘˜ ë‹¤ì—ì„œ ì°¾ì„ ê²ƒì´ê¸° ë•Œë¬¸.\n",
    "        df = df[~df['Edited74_On'].str.contains('GAGACG', na=False, case=False)]\n",
    "        df = df[~df['Edited74_On'].str.contains('CGTCTC', na=False, case=False)]\n",
    "\n",
    "        ## ì¶”ê°€!! spacer ë¶€ë¶„ì—ì„œ BsmBI siteê°€ ë“¤ì–´ìˆëŠ” ê²ƒ ì œê±°í•˜ê¸°\n",
    "        ## WT targetì—ì„œ spacer ë¶€ë¶„ë§Œ ë½‘ì€ ê²ƒì„ ìƒˆ columnìœ¼ë¡œ ë„£ê³ , ë˜‘ê°™ì´ ì œê±°í•´ì£¼ë©´ ëœë‹¤. \n",
    "        df['gN19'] = df['WT74_On'][5:24]\n",
    "        df = df[~df['gN19'].str.contains('GAGACG', na=False, case=False)]\n",
    "        df = df[~df['gN19'].str.contains('CGTCTC', na=False, case=False)]\n",
    "\n",
    "        ## 2. targetë§Œ seriesë¡œ ê°€ì ¸ì˜¨ ë‹¤ìŒ, unique valueë§Œ ë‚¨ê¸´ë‹¤. sortingì„ ë¨¼ì € í–ˆê¸° ë•Œë¬¸ì— DeepPrime score ë†’ì€ ê²ƒì´ ê°€ì¥ ë¨¼ì € ë‚˜ì˜¨ ìˆœìœ¼ë¡œ ì •ë ¬ëœë‹¤. = srs_target (srs = series ì•½ì)\n",
    "        srs_target = df.WT74_On.unique()\n",
    "\n",
    "        ## 3. sort_values ëœ dfë¥¼ Seed targetìœ¼ë¡œ groupbyí•œë‹¤.\n",
    "        grouped_df = df.groupby('WT74_On')\n",
    "\n",
    "        ## 4. ser_targetì—ì„œ ì•ì—ì„œ 3ê°œì— ëŒ€í•´ì„œë§Œ (top3) ê° seed targetë§ˆë‹¤ top 3ê°œì”© ê³ ë¥¸ë‹¤. ì´ 3ê°œì˜ seedì— ëŒ€í•´ 9ê°œì˜ pegRNAê°€ ì„ ì •ë˜ì–´ì•¼ í•¨.\n",
    "        ## Seed Targetì´ 3ê°œ ì´í•˜ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ forë¬¸ìœ¼ë¡œ len(srs_target)ë§Œí¼ ëŒë¦¬ë‹¤ê°€ 3ê°œ ë„˜ì–´ê°€ëŠ” idx 3 ë„˜ê¸°ëŠ” ìˆœê°„ continue.\n",
    "        \n",
    "        list_df_temp = []\n",
    "\n",
    "        for idx, trgt in enumerate(srs_target):\n",
    "            df_top3_pegrna = grouped_df.get_group(trgt).head(2)\n",
    "            list_df_temp.append(df_top3_pegrna)\n",
    "\n",
    "            if idx == 2: break\n",
    "        \n",
    "        ## 5. Output = ì´ë ‡ê²Œ ë½‘íŒ pegRNA ì •ë³´ë“¤ì€ ìƒˆ dataframeë“¤ì— ë‹´ì•„ì¤€ë‹¤. ê·¸ë¦¬ê³  ê·¸ ì•ˆì—ì„œ rank columnì„ ì¶”ê°€í•´ì¤€ë‹¤. ê·¸ë¦¬ê³  ìµœì¢… output dfì— ë„£ì–´ì¤€ë‹¤. \n",
    "        df_temp = pd.concat(list_df_temp)\n",
    "        df_temp['rank'] = df_temp.DeepPrime_score.rank(ascending=False)\n",
    "        \n",
    "        df_out = pd.concat([df_out, df_temp])\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run ###\n",
    "\n",
    "target_list = ['ABL1_ex4', 'ABL1_ex5', 'ABL1_ex6', 'ABL1_ex7', 'ABL1_ex8', 'ABL1_ex9']\n",
    "pe_sys = ['PE2max']\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "\n",
    "for pe in pe_sys:\n",
    "    list_out = []\n",
    "\n",
    "    for gene in target_list:\n",
    "        file_dir = '%s/output/%s' %(base_dir, gene)\n",
    "\n",
    "        df_out = make_top_pegrna_list(file_dir, pe)\n",
    "        list_out.append(df_out)\n",
    "\n",
    "    df = pd.concat(list_out)\n",
    "    df.to_csv('%s/ABL1_top_pegRNAs_%s_220802_BsmBI_filtered_Top6.csv' % (base_dir, pe), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
